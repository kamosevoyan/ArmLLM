{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -q faiss-gpu datasets \\\n",
    "               evaluate transformers[sentencepiece] \\\n",
    "               rank_bm25 pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.functional import tensordot\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CosineEmbeddingLoss\n",
    "from torch import Tensor\n",
    "\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DPRContextEncoder\n",
    "from typing import List, Dict\n",
    "\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv(\"imdb_top_10k.csv\")\n",
    "# df = df[['Movie Name', 'Genre', 'Plot', 'Directors']]\n",
    "# df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contexts(df: pd.DataFrame) -> List[Dict]:\n",
    "    contexts = []\n",
    "    for i, row in df.iterrows():\n",
    "        contexts.append(\n",
    "            {\n",
    "                \"title\": row[\"Movie Name\"],\n",
    "                \"text\": row[\"Plot\"],\n",
    "                \"meta\": {\n",
    "                    \"genre\": row[\"Genre\"],\n",
    "                    \"director\": row[\"Directors\"],\n",
    "                    \"votes\": row[\"Votes\"],\n",
    "                    \"rating\": row[\"Rating\"],\n",
    "                    \"metascore\": row[\"Metascore\"],\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    return contexts\n",
    "\n",
    "\n",
    "contexts = get_contexts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Implementation of BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "\n",
    "class BM25Search:\n",
    "    def __init__(self, documents: List[str]):\n",
    "        self.documents = documents\n",
    "        self.tokenized_documents = [document.split() for document in documents]\n",
    "        self.bm25 = BM25Okapi(self.tokenized_documents)\n",
    "\n",
    "    def search(self, query: str, top_k: int = 5) -> List[int]:\n",
    "        tokenized_query = query.split()\n",
    "        doc_scores = self.bm25.get_scores(tokenized_query)\n",
    "        # print(doc_scores)\n",
    "        sorted_indices = np.argsort(doc_scores)[::-1]\n",
    "        return sorted_indices[:top_k]\n",
    "\n",
    "\n",
    "bm25_search = BM25Search([context[\"text\"] for context in contexts])\n",
    "query = \"Batman\"\n",
    "retrieved_indices = bm25_search.search(query)\n",
    "print(retrieved_indices)\n",
    "for i in retrieved_indices:\n",
    "    print(contexts[i][\"title\"], contexts[i][\"text\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the retriever in your favorite package for RAG as well, i.e. LangChain, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "retriever = BM25Retriever.from_texts([context[\"text\"] for context in contexts])\n",
    "retrieved_indices = retriever.invoke(query)\n",
    "retrieved_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_freq(term: str, document: str) -> int:\n",
    "    return document.count(term)\n",
    "\n",
    "\n",
    "def get_doc_length(document: str):\n",
    "    return len(document.split())\n",
    "\n",
    "\n",
    "def get_avg_doc_length(documents: str):\n",
    "    res = [get_doc_length(d) for d in documents]\n",
    "    return sum(res) / len(res)\n",
    "\n",
    "\n",
    "def get_num_containing_docs(term: str, documents: List[str]):\n",
    "    return sum(list(map(lambda x: term in x, documents)))\n",
    "\n",
    "\n",
    "def bm25(\n",
    "    term: str, document: str, documents: List[str], k1: float = 1.5, b: float = 0.75\n",
    ") -> float:\n",
    "\n",
    "    term_freq = get_term_freq(term, document)\n",
    "    N = len(documents)\n",
    "    D = get_doc_length(document)\n",
    "    avgdl = get_avg_doc_length(documents)\n",
    "\n",
    "    tf = term_freq * (k1 + 1) / (term_freq + k1 * (1 - b + b * D / avgdl))\n",
    "    nq = get_num_containing_docs(term, documents)\n",
    "    idf = np.log((N - nq + 0.5) / (nq + 0.5) + 1)\n",
    "\n",
    "    return tf * idf\n",
    "\n",
    "\n",
    "def bm25_similarity(query: str, document: str, documents: List[str]) -> float:\n",
    "    query_terms = query.split()\n",
    "    return sum(bm25(term, document, documents) for term in query_terms)\n",
    "\n",
    "\n",
    "def get_bm25_topk(query: str, documents: List[str], k: int = 5) -> List[int]:\n",
    "    scores = [bm25_similarity(query, document, documents) for document in documents]\n",
    "    return sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]\n",
    "\n",
    "\n",
    "# test\n",
    "retrieved_indices = get_bm25_topk(query, [context[\"text\"] for context in contexts])\n",
    "for i in retrieved_indices:\n",
    "    print(contexts[i][\"title\"], contexts[i][\"text\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make it a huggingface dataset out of pure convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dataset = Dataset.from_pandas(df)\n",
    "movie_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_text(data):\n",
    "\n",
    "    return {\n",
    "        \"text\": data[\"Movie Name\"]\n",
    "        + \" \\n\"\n",
    "        + data[\"Genre\"]\n",
    "        + \" \\n\"\n",
    "        + data[\"Plot\"]\n",
    "        + \" \\n\"\n",
    "        + data[\"Directors\"]\n",
    "        + \" \\n\"\n",
    "        + str(data[\"Votes\"])\n",
    "        + \" \\n\"\n",
    "        + str(data[\"Rating\"])\n",
    "        + \" \\n\"\n",
    "        + str(data[\"Metascore\"])\n",
    "    }\n",
    "\n",
    "\n",
    "movie_dataset = movie_dataset.map(concatenate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_embedder(nn.Module):\n",
    "    def __init__(self, feat_extractor_name: str = \"\"):\n",
    "        \"\"\"Transformer Embedding model\n",
    "\n",
    "        Args:\n",
    "            feat_extractor_name (str, optional): Name of the feature extracator from HF hub or torch Hub.\n",
    "        \"\"\"\n",
    "        super(Transformer_embedder, self).__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.feat_extractor_name = feat_extractor_name\n",
    "\n",
    "        if \"dpr\" in feat_extractor_name.lower():\n",
    "            feat_extractor = DPRContextEncoder.from_pretrained(feat_extractor_name)\n",
    "        else:\n",
    "            feat_extractor = AutoModel.from_pretrained(feat_extractor_name)\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(feat_extractor_name)\n",
    "\n",
    "        self.normalize = True\n",
    "        self.feat_extractor = feat_extractor\n",
    "        self.embeding_shape = self.get_extractor_output_shape()\n",
    "\n",
    "    def get_extractor_output_shape(self):\n",
    "        last_layer = list(self.feat_extractor.named_children())[-1]\n",
    "\n",
    "        if hasattr(list(last_layer[1].modules())[1], \"out_features\"):\n",
    "            shape = list(last_layer[1].modules())[1].out_features\n",
    "        else:\n",
    "            shape = self.feat_extractor.config.hidden_size\n",
    "\n",
    "        return shape\n",
    "\n",
    "    def mean_pooling(self, model_output: Tensor, attention_mask: Tensor):\n",
    "        token_embeddings = model_output[\n",
    "            0\n",
    "        ]  # First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = (\n",
    "            attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        )\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "            input_mask_expanded.sum(1), min=1e-9\n",
    "        )\n",
    "\n",
    "    def pool(self, embedding: Tensor, attention_mask: Tensor, pool_type: str = \"mean\"):\n",
    "\n",
    "        if \"mean\" in pool_type:\n",
    "            pooled = self.mean_pooling(embedding, attention_mask)\n",
    "        else:\n",
    "            pooled = embedding.last_hidden_state[:, 0, :]\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def __call__(\n",
    "        self, input_ids: Tensor, attention_mask: Tensor, labels: Tensor = None, **kwargs\n",
    "    ):\n",
    "\n",
    "        embedding = self.feat_extractor(input_ids, attention_mask)\n",
    "\n",
    "        if \"dpr\" in self.feat_extractor_name.lower():\n",
    "            pooled = embedding.pooler_output\n",
    "        else:\n",
    "            pooled = self.pool(embedding, attention_mask, pool_type=\"mean\")\n",
    "\n",
    "        if self.normalize:\n",
    "            pooled = F.normalize(pooled, p=2, dim=1)\n",
    "\n",
    "        return pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "\n",
    "# The following is a bigger model and might require slight modification in the code\n",
    "# follow this link for more details: https://huggingface.co/intfloat/e5-mistral-7b-instruct\n",
    "# model_ckpt = \"intfloat/e5-mistral-7b-instruct\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedder = Transformer_embedder(model_ckpt)\n",
    "embedder = embedder.to(device)\n",
    "\n",
    "\n",
    "def get_embeddings(text_list):\n",
    "    encoded_input = embedder.tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    embedder.eval()\n",
    "    with torch.inference_mode():\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "        model_output = embedder(**encoded_input)\n",
    "    return model_output\n",
    "\n",
    "\n",
    "# the reason to save as numpy is for further FAISS indexing\n",
    "embeddings_dataset = movie_dataset.map(\n",
    "    lambda x: {\"embeddings\": get_embeddings(x[\"text\"]).cpu().detach().numpy()[0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make embeddings numpy array\n",
    "embeddings_dataset.set_format(\n",
    "    type=\"numpy\",\n",
    "    columns=[\n",
    "        \"embeddings\",\n",
    "        \"text\",\n",
    "        \"Movie Name\",\n",
    "        \"Genre\",\n",
    "        \"Plot\",\n",
    "        \"Directors\",\n",
    "        \"Votes\",\n",
    "        \"Rating\",\n",
    "        \"Metascore\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dataset[1][\"embeddings\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Armenia\"\n",
    "question_embedding = get_embeddings([question]).cpu().detach().numpy()[0]\n",
    "question_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=5\n",
    ")\n",
    "samples = {k: v for k, v in samples.items() if k != \"embeddings\"}\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in samples_df.iterrows():\n",
    "    print(f\"Series Title: {row['Movie Name']}\")\n",
    "    print(f\"Overview: {row['Plot']}\")\n",
    "    print(f\"Genre: {row['Genre']}\")\n",
    "    print(f\"Scores: {row['scores']}\")\n",
    "    print(f\"Votes: {row['Votes']}\")\n",
    "    print(f\"Rating: {row['Rating']}\")\n",
    "    print(f\"Metascore: {row['Metascore']}\")\n",
    "    print(f\"Directors: {row['Directors']}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save only the embeddings\n",
    "embeddings = embeddings_dataset[\"embeddings\"]\n",
    "np.save(\"imdb_top_10k_embeddings.npy\", embeddings)\n",
    "\n",
    "# save the dataset\n",
    "embeddings_dataset.drop_index(\"embeddings\")\n",
    "embeddings_dataset.save_to_disk(\"imdb_top_10k_embeddings_dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
