{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Indexing Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -q hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.functional import tensordot\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CosineEmbeddingLoss\n",
    "from torch import Tensor\n",
    "\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DPRContextEncoder\n",
    "from typing import List, Dict\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import hnswlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make it a huggingface dataset out of pure convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_dataset = Dataset.load_from_disk(\"imdb_top_10k_embeddings_dataset\")\n",
    "imdb_embeddings = np.load(\"imdb_top_10k_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_embedder(nn.Module):\n",
    "    def __init__(self, feat_extractor_name: str = \"\"):\n",
    "        \"\"\"Transformer Embedding model\n",
    "\n",
    "        Args:\n",
    "            feat_extractor_name (str, optional): Name of the feature extracator from HF hub or torch Hub.\n",
    "        \"\"\"\n",
    "        super(Transformer_embedder, self).__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.feat_extractor_name = feat_extractor_name\n",
    "\n",
    "        if \"dpr\" in feat_extractor_name.lower():\n",
    "            feat_extractor = DPRContextEncoder.from_pretrained(feat_extractor_name)\n",
    "        else:\n",
    "            feat_extractor = AutoModel.from_pretrained(feat_extractor_name)\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(feat_extractor_name)\n",
    "\n",
    "        self.normalize = True\n",
    "        self.feat_extractor = feat_extractor\n",
    "        self.embeding_shape = self.get_extractor_output_shape()\n",
    "\n",
    "    def get_extractor_output_shape(self):\n",
    "        last_layer = list(self.feat_extractor.named_children())[-1]\n",
    "\n",
    "        if hasattr(list(last_layer[1].modules())[1], \"out_features\"):\n",
    "            shape = list(last_layer[1].modules())[1].out_features\n",
    "        else:\n",
    "            shape = self.feat_extractor.config.hidden_size\n",
    "\n",
    "        return shape\n",
    "\n",
    "    def mean_pooling(self, model_output: Tensor, attention_mask: Tensor):\n",
    "        token_embeddings = model_output[\n",
    "            0\n",
    "        ]  # First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = (\n",
    "            attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        )\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "            input_mask_expanded.sum(1), min=1e-9\n",
    "        )\n",
    "\n",
    "    def pool(self, embedding: Tensor, attention_mask: Tensor, pool_type: str = \"mean\"):\n",
    "\n",
    "        if \"mean\" in pool_type:\n",
    "            pooled = self.mean_pooling(embedding, attention_mask)\n",
    "        else:\n",
    "            pooled = embedding.last_hidden_state[:, 0, :]\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def __call__(\n",
    "        self, input_ids: Tensor, attention_mask: Tensor, labels: Tensor = None, **kwargs\n",
    "    ):\n",
    "\n",
    "        # print('input_ids.shape: ', input_ids.shape)\n",
    "        embedding = self.feat_extractor(input_ids, attention_mask)\n",
    "\n",
    "        if \"dpr\" in self.feat_extractor_name.lower():\n",
    "            pooled = embedding.pooler_output\n",
    "        else:\n",
    "            pooled = self.pool(embedding, attention_mask, pool_type=\"mean\")\n",
    "        # print('embedding.shape: ', embedding.last_hidden_state.shape)\n",
    "        # last_hidden_states = embedding.last_hidden_state\n",
    "        # print('last_hidden_states.shape: ', last_hidden_states.shape)\n",
    "        # pooled = self.pool(last_hidden_states, attention_mask, pool_type='mean')\n",
    "        # print('pooled.shape: ', pooled.shape)\n",
    "\n",
    "        if self.normalize:\n",
    "            pooled = F.normalize(pooled, p=2, dim=1)\n",
    "\n",
    "        # print(pooled.shape)\n",
    "        return pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "\n",
    "# The following is a bigger model and might require slight modification in the code\n",
    "# follow this link for more details: https://huggingface.co/intfloat/e5-mistral-7b-instruct\n",
    "# model_ckpt = \"intfloat/e5-mistral-7b-instruct\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedder = Transformer_embedder(model_ckpt)\n",
    "embedder = embedder.to(device)\n",
    "\n",
    "\n",
    "def get_embeddings(text_list):\n",
    "    encoded_input = embedder.tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    embedder.eval()\n",
    "    with torch.inference_mode():\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "        model_output = embedder(**encoded_input)\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Armenia\"\n",
    "question_embedding = get_embeddings([question]).cpu().detach().numpy()[0]\n",
    "question_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted File Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverted file indexing is a technique used to index documents in a corpus. It is a data structure that maps terms to the documents that contain them. The inverted file index is a dictionary where the keys are terms and the values are lists of document IDs. The inverted file index is used to quickly find documents that contain a given term.\n",
    "\n",
    "Mathematically, the inverted file index is defined as follows:\n",
    "\n",
    "$$\n",
    "I = \\{t_1: [d_1, d_2, \\ldots, d_n], t_2: [d_1, d_2, \\ldots, d_n], \\ldots, t_m: [d_1, d_2, \\ldots, d_n]\\}\n",
    "$$\n",
    "\n",
    "Where $I$ is the inverted file index, $t_i$ is the $i$-th term, and $d_i$ is the $i$-th document ID.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "\n",
    "class IVFFlatIndexer:\n",
    "    def __init__(self, n_clusters: int = 100, n_init: int = 10, max_iter: int = 300):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_init = n_init\n",
    "        self.max_iter = max_iter\n",
    "        self.index = MiniBatchKMeans(\n",
    "            n_clusters=self.n_clusters,\n",
    "            n_init=self.n_init,\n",
    "            max_iter=self.max_iter,\n",
    "            init_size=3 * self.n_clusters,\n",
    "        )\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.index.fit(X)\n",
    "\n",
    "    def search(self, X, top_k=5):\n",
    "        return self.index.predict(X)\n",
    "\n",
    "    def get_cluster_centers(self):\n",
    "        return self.index.cluster_centers_\n",
    "\n",
    "    def get_cluster_labels(self):\n",
    "        return self.index.labels_\n",
    "\n",
    "\n",
    "indexer = IVFFlatIndexer(n_clusters=100)\n",
    "indexer.fit(imdb_embeddings)\n",
    "\n",
    "print(indexer.search(question_embedding.reshape(1, -1)))\n",
    "\n",
    "\n",
    "def get_top_k_similar(question_embedding, embeddings, indexer, k=5):\n",
    "    cluster_id = indexer.search(question_embedding.reshape(1, -1))\n",
    "    cluster_embeddings = embeddings[indexer.get_cluster_labels() == cluster_id]\n",
    "    distances = np.dot(cluster_embeddings, question_embedding)\n",
    "    top_k_indices = np.argsort(distances)[::-1][:k]\n",
    "    return top_k_indices\n",
    "\n",
    "\n",
    "top_k_indices = get_top_k_similar(question_embedding, imdb_embeddings, indexer, k=5)\n",
    "top_k_indices\n",
    "\n",
    "print(\"Question: \", question)\n",
    "print(\"Top 5 similar movies:\")\n",
    "print(\"=\" * 100)\n",
    "for idx in top_k_indices:\n",
    "    print(imdb_dataset[idx.item()][\"Movie Name\"])\n",
    "    print(imdb_dataset[idx.item()][\"Plot\"])\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locality Sensitive Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local sensitive hashing (LSH) is a technique used to find similar items in a large dataset. LSH is used to reduce the dimensionality of the data and to find similar items in the reduced space. LSH is used in many applications, such as near-duplicate detection, recommendation systems, and clustering.\n",
    "\n",
    "Mathematically, LSH is defined as follows:\n",
    "\n",
    "$$\n",
    "h(x) = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\text{if } x \\geq t \\\\\n",
    "0 & \\text{if } x < t\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Where $h(x)$ is the hash function, $x$ is the input value, and $t$ is the threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSHIndexer:\n",
    "    def __init__(self, n_bits: int = 8):\n",
    "        self.n_bits = n_bits\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.index = np.packbits(X > 0, axis=1)\n",
    "\n",
    "    def search(self, X, top_k=5):\n",
    "        query = np.packbits(X > 0, axis=1)\n",
    "        distances = np.dot(query, self.index.T)\n",
    "        top_k_indices = np.argsort(distances)[::-1][:top_k]\n",
    "        return top_k_indices\n",
    "\n",
    "    def get_index(self):\n",
    "        return self.index\n",
    "\n",
    "\n",
    "indexer = LSHIndexer(n_bits=8)\n",
    "indexer.fit(imdb_embeddings)\n",
    "\n",
    "top_k_indices = indexer.search(question_embedding.reshape(1, -1))\n",
    "top_k_indices = top_k_indices[0][:5]\n",
    "\n",
    "\n",
    "print(\"Question: \", question)\n",
    "print(\"Top 5 similar movies:\")\n",
    "print(\"=\" * 100)\n",
    "for idx in top_k_indices:\n",
    "    idx = idx.item()\n",
    "    print(imdb_dataset[idx][\"Movie Name\"])\n",
    "    print(imdb_dataset[idx][\"Plot\"])\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product quantization is a technique used to compress high-dimensional vectors into low-dimensional vectors. Product quantization is used to reduce the storage and computation costs of working with high-dimensional vectors. Product quantization is used in many applications, such as image retrieval, text search, and recommendation systems.\n",
    "\n",
    "Mathematically, product quantization is defined as follows:\n",
    "\n",
    "$$\n",
    "Q(x) = \\sum_{i=1}^{n} c_i \\cdot q_i(x)\n",
    "$$\n",
    "\n",
    "Where $Q(x)$ is the quantized vector, $x$ is the input vector, $c_i$ is the $i$-th codebook vector, and $q_i(x)$ is the $i$-th quantization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductQuantization:\n",
    "    def __init__(self, sentence_embeddings, n_subvectors=8):\n",
    "        \"\"\"\n",
    "        Product Quantization Index\n",
    "\n",
    "        Args:\n",
    "            sentence_embeddings (np.array): Array of sentence embeddings\n",
    "            n_subvectors (int): Number of subvectors to divide each embedding into\n",
    "        \"\"\"\n",
    "        # Subspace dimensionality\n",
    "        self.d = sentence_embeddings.shape[1] // n_subvectors\n",
    "        # Number of subvectors\n",
    "        self.m = n_subvectors\n",
    "\n",
    "        # Generate random projection matrix\n",
    "        self.R = np.random.randn(self.d * self.m, self.d)\n",
    "        self.R /= np.linalg.norm(self.R, axis=0)\n",
    "\n",
    "        # Project sentence embeddings onto subspaces\n",
    "        self.subspace_embeddings = np.dot(sentence_embeddings, self.R)\n",
    "\n",
    "        # Quantize subspace embeddings\n",
    "        self.quantized_subspace_embeddings = np.round(self.subspace_embeddings / self.d)\n",
    "\n",
    "    def search(self, query_embedding, top_k=1):\n",
    "        \"\"\"\n",
    "        Search for the most similar sentences to a query embedding\n",
    "\n",
    "        Args:\n",
    "            query_embedding (np.array): Query embedding\n",
    "            top_k (int): Number of similar sentences to return\n",
    "\n",
    "        Returns:\n",
    "            list: List of indices of similar sentences\n",
    "        \"\"\"\n",
    "        # Project query embedding onto subspaces\n",
    "        query_subspace_embeddings = np.dot(query_embedding, self.R)\n",
    "\n",
    "        # Quantize query subspace embeddings\n",
    "        quantized_query_subspace_embeddings = np.round(\n",
    "            query_subspace_embeddings / self.d\n",
    "        )\n",
    "\n",
    "        # Find nearest neighbors in each subspace\n",
    "        nearest_neighbors = []\n",
    "        for i in range(self.m):\n",
    "            distances = np.linalg.norm(\n",
    "                self.quantized_subspace_embeddings[:, i]\n",
    "                - quantized_query_subspace_embeddings[i],\n",
    "                ord=2,\n",
    "            )\n",
    "            nearest_neighbors.append(np.argsort(distances)[:top_k])\n",
    "\n",
    "        # Combine nearest neighbors from each subspace\n",
    "        combined_nearest_neighbors = set()\n",
    "        for neighbors in nearest_neighbors:\n",
    "            combined_nearest_neighbors.update(neighbors)\n",
    "\n",
    "        return list(combined_nearest_neighbors)\n",
    "\n",
    "\n",
    "product_quantizer = ProductQuantization(imdb_embeddings, n_subvectors=16)\n",
    "top_k_indices = product_quantizer.search(question_embedding, top_k=5)\n",
    "print(top_k_indices)\n",
    "\n",
    "print(\"Question: \", question)\n",
    "print(\"Top 5 similar movies:\")\n",
    "print(\"=\" * 100)\n",
    "for idx in top_k_indices:\n",
    "    idx = idx.item()\n",
    "    print(imdb_dataset[idx][\"Movie Name\"])\n",
    "    print(imdb_dataset[idx][\"Plot\"])\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigable Small World Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigable small world graphs are a technique used to build a graph that can be used to efficiently search for similar items in a large dataset. Navigable small world graphs are used to reduce the search time and space required to find similar items in a large dataset. \n",
    "\n",
    "Mathematically, navigable small world graphs are defined as follows:\n",
    "\n",
    "$$\n",
    "G = (V, E)\n",
    "$$\n",
    "\n",
    "Where $G$ is the navigable small world graph, $V$ is the set of vertices, and $E$ is the set of edges.\n",
    "\n",
    "The algorithm for building a navigable small world graph is as follows:\n",
    "\n",
    "1. Initialize the graph with a single vertex.\n",
    "2. Add a new vertex to the graph.\n",
    "3. Connect the new vertex to the nearest vertex in the graph.\n",
    "4. Repeat steps 2 and 3 until all vertices are connected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HNSWIndexer:\n",
    "\n",
    "    def __init__(self, sentence_embeddings, ef=50, M=16):\n",
    "        \"\"\"\n",
    "        HNSW Index\n",
    "\n",
    "        Args:\n",
    "            sentence_embeddings (np.array): Array of sentence embeddings\n",
    "            ef (int): Number of neighbors to inspect during search\n",
    "            M (int): Number of neighbors to keep in graph\n",
    "        \"\"\"\n",
    "        self.ef = ef\n",
    "        self.M = M\n",
    "        self.index = hnswlib.Index(space=\"cosine\", dim=sentence_embeddings.shape[1])\n",
    "        self.index.init_index(\n",
    "            max_elements=sentence_embeddings.shape[0], ef_construction=self.ef, M=self.M\n",
    "        )\n",
    "        self.index.add_items(sentence_embeddings)\n",
    "\n",
    "    def search(self, query_embedding, top_k=1):\n",
    "        \"\"\"\n",
    "        Search for the most similar sentences to a query embedding\n",
    "\n",
    "        Args:\n",
    "            query_embedding (np.array): Query embedding\n",
    "            top_k (int): Number of similar sentences to return\n",
    "\n",
    "        Returns:\n",
    "            list: List of indices of similar sentences\n",
    "        \"\"\"\n",
    "        self.index.set_ef(self.ef)\n",
    "        labels, distances = self.index.knn_query(query_embedding, k=top_k)\n",
    "        return labels\n",
    "\n",
    "\n",
    "hnsw_indexer = HNSWIndexer(imdb_embeddings)\n",
    "top_k_indices = hnsw_indexer.search(question_embedding, top_k=5)\n",
    "print(top_k_indices)\n",
    "\n",
    "print(\"Question: \", question)\n",
    "print(\"Top 5 similar movies:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for idx in top_k_indices[0]:\n",
    "    idx = idx.item()\n",
    "    print(imdb_dataset[idx][\"Movie Name\"])\n",
    "    print(imdb_dataset[idx][\"Plot\"])\n",
    "    print(\"=\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
