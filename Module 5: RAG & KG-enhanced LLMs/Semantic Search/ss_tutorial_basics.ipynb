{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-gpu\n",
    "!pip install datasets evaluate transformers[sentencepiece]\n",
    "!pip install rank_bm25 pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.functional import tensordot\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CosineEmbeddingLoss\n",
    "from torch import Tensor\n",
    "\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DPRContextEncoder\n",
    "from typing import List, Dict\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "df = pd.read_csv(\"imdb_top_10k.csv\")\n",
    "# df = df[['Movie Name', 'Genre', 'Plot', 'Directors']]\n",
    "# df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contexts(df: pd.DataFrame) -> List[Dict]:\n",
    "    contexts = []\n",
    "    for i, row in df.iterrows():\n",
    "        contexts.append({\n",
    "            'title': row['Movie Name'],\n",
    "            'text': row['Plot'],\n",
    "            'meta': {\n",
    "                'genre': row['Genre'],\n",
    "                'director': row['Directors'],\n",
    "                'votes': row['Votes'],\n",
    "                'rating': row['Rating'],\n",
    "                'metascore': row['Metascore'],\n",
    "            }\n",
    "        })\n",
    "    return contexts\n",
    "\n",
    "contexts = get_contexts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Implementation of BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "class BM25Search:\n",
    "    def __init__(self, documents: List[str]):\n",
    "        self.documents = documents\n",
    "        self.tokenized_documents = [document.split() for document in documents]\n",
    "        self.bm25 = BM25Okapi(self.tokenized_documents)\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 5) -> List[int]:\n",
    "        tokenized_query = query.split()\n",
    "        doc_scores = self.bm25.get_scores(tokenized_query)\n",
    "        # print(doc_scores)\n",
    "        sorted_indices = np.argsort(doc_scores)[::-1]\n",
    "        return sorted_indices[:top_k]\n",
    "    \n",
    "bm25_search = BM25Search([context['text'] for context in contexts])\n",
    "query = \"Batman\"\n",
    "retrieved_indices = bm25_search.search(query)\n",
    "print(retrieved_indices)\n",
    "for i in retrieved_indices:\n",
    "    print(contexts[i]['title'], contexts[i]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the retriever in your favorite package for RAG as well, i.e. LangChain, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "retriever = BM25Retriever.from_texts([context['text'] for context in contexts])\n",
    "retrieved_indices = retriever.invoke(query)\n",
    "retrieved_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_freq(term: str, document: str) -> int:    \n",
    "    \n",
    "    return document.count(term)\n",
    "\n",
    "def get_doc_length(document: str):\n",
    "    return len(document.split())\n",
    "\n",
    "def get_avg_doc_length(documents: str):\n",
    "    \n",
    "    res = [get_doc_length(d) for d in documents]\n",
    "    \n",
    "    return sum(res) / len(res)\n",
    "\n",
    "def bm25(term: str, document: str, documents: List[str], k1: float = 1.5, b: float = 0.75) -> float:\n",
    "    \n",
    "    fqD = term_freq(term, document)\n",
    "    N = len(documents)\n",
    "    D = get_doc_length(document)\n",
    "    avgdl = get_avg_doc_length(documents)\n",
    "    \n",
    "    tf = fqD*(k1 + 1) / (fqD +k1*(1 - b + b*D/avgdl))    \n",
    "    nq = sum(list(map(lambda x: term in x, documents)))    \n",
    "    idf = np.log((N - nq + 0.5)/(nq + 0.5) + 1)\n",
    "    \n",
    "    return tf * idf\n",
    "    \n",
    "def bm25_similarity(query: str, document: str, documents: List[str]) -> float:\n",
    "    query_terms = query.split()\n",
    "    return sum(bm25(term, document, documents) for term in query_terms)\n",
    "\n",
    "def get_bm25_topk(query: str, documents: List[str], k: int = 5) -> List[int]:\n",
    "    scores = [bm25_similarity(query, document, documents) for document in documents]\n",
    "    return sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]\n",
    "\n",
    "#test\n",
    "retrieved_indices = get_bm25_topk(query, [context['text'] for context in contexts])\n",
    "for i in retrieved_indices:\n",
    "    print(contexts[i]['title'], contexts[i]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make it a huggingface dataset out of pure convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "movie_dataset = Dataset.from_pandas(df)\n",
    "movie_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_text(data):\n",
    "    \n",
    "    return {\"text\": data['Movie Name'] + \" \\n\" + data['Genre'] + \" \\n\" + data['Plot'] + \" \\n\" + data['Directors'] + \" \\n\" + str(data['Votes']) + \" \\n\" + str(data['Rating']) + \" \\n\" + str(data['Metascore'])}\n",
    "\n",
    "movie_dataset = movie_dataset.map(concatenate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_embedder(nn.Module):\n",
    "    def __init__(self, feat_extractor_name: str = ''):\n",
    "        \"\"\"Transformer Embedding model\n",
    "\n",
    "        Args:\n",
    "            feat_extractor_name (str, optional): Name of the feature extracator from HF hub or torch Hub.\n",
    "        \"\"\"        \n",
    "        super(Transformer_embedder, self).__init__()\n",
    "        \n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.feat_extractor_name = feat_extractor_name\n",
    "\n",
    "        if 'dpr' in feat_extractor_name.lower():\n",
    "            feat_extractor = DPRContextEncoder.from_pretrained(feat_extractor_name)\n",
    "        else:\n",
    "            feat_extractor = AutoModel.from_pretrained(feat_extractor_name)\n",
    "            \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(feat_extractor_name)\n",
    "\n",
    "        \n",
    "        self.normalize = True\n",
    "        self.feat_extractor = feat_extractor\n",
    "        self.embeding_shape = self.get_extractor_output_shape() \n",
    "                            \n",
    "\n",
    "    def get_extractor_output_shape(self):\n",
    "        last_layer = list(self.feat_extractor.named_children())[-1]\n",
    "\n",
    "        if hasattr( list(last_layer[1].modules())[1] , 'out_features'):\n",
    "            shape = list(last_layer[1].modules())[1].out_features\n",
    "        else:\n",
    "            shape = self.feat_extractor.config.hidden_size\n",
    "\n",
    "        return shape\n",
    "    \n",
    "    def mean_pooling(self, model_output:Tensor, attention_mask:Tensor):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "    def pool(self, embedding:Tensor, attention_mask:Tensor, pool_type:str = 'mean'):\n",
    "        \n",
    "        if 'mean' in pool_type:\n",
    "            pooled = self.mean_pooling(embedding, attention_mask)\n",
    "        else:\n",
    "            pooled = embedding.last_hidden_state[:, 0, :]\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def __call__(self, input_ids:Tensor, attention_mask:Tensor, labels: Tensor = None, **kwargs):\n",
    "\n",
    "        #TODO implement this function\n",
    "        \n",
    "        embedding = self.feat_extractor(input_ids, attention_mask)\n",
    "        \n",
    "        if \"dpr\" in self.feat_extractor_name.lower():\n",
    "            pooled = embedding.pooler_output\n",
    "        else:\n",
    "            pooled = self.pool(embedding, attention_mask, pool_type=\"mean\")\n",
    "\n",
    "        if self.normalize:\n",
    "            pooled = F.normalize(pooled, p=2, dim=1)\n",
    "            \n",
    "        return pooled\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b2689303f14f58ac72d90799d44f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3d435afc9c48359698581767aefaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f7e6a10ec844c4a5a2453a51251f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a431326a28134896914dba4c4ffa0d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36262a7d907f453d806cc7ad2a20ab7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7add7f6bb8e14999b5c453fc922d6aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ead2a4982f486588d3acd1da4dbbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "\n",
    "#The following is a bigger model and might require slight modification in the code\n",
    "# follow this link for more details: https://huggingface.co/intfloat/e5-mistral-7b-instruct\n",
    "# model_ckpt = \"intfloat/e5-mistral-7b-instruct\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedder = Transformer_embedder(model_ckpt)\n",
    "embedder = embedder.to(device)\n",
    "\n",
    "def get_embeddings(text_list):\n",
    "    encoded_input = embedder.tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    embedder.eval()\n",
    "    with torch.inference_mode():\n",
    "        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "        model_output = embedder(**encoded_input)\n",
    "    return model_output\n",
    "\n",
    "#the reason to save as numpy is for further FAISS indexing\n",
    "embeddings_dataset = movie_dataset.map(\n",
    "    lambda x: {\"embeddings\": get_embeddings(x[\"text\"]).cpu().detach().numpy()[0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make embeddings numpy array\n",
    "embeddings_dataset.set_format(type=\"numpy\", columns=[\"embeddings\", \"text\", \"Movie Name\", \"Genre\", \"Plot\", \"Directors\", \"Votes\", \"Rating\", \"Metascore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dataset[1][\"embeddings\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96f0133f0ce49d0838614dc142e958f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ID', 'Movie Name', 'Rating', 'Runtime', 'Genre', 'Metascore', 'Plot', 'Directors', 'Stars', 'Votes', 'Gross', 'Link', 'text', 'embeddings'],\n",
       "    num_rows: 9999\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Hitler\"\n",
    "question_embedding = get_embeddings([question]).cpu().detach().numpy()[0]\n",
    "question_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=5\n",
    ")\n",
    "\n",
    "#save only the embeddings\n",
    "embeddings = embeddings_dataset[\"embeddings\"]\n",
    "np.save(\"imdb_top_10k_embeddings.npy\", embeddings)\n",
    "\n",
    "#save the dataset\n",
    "# embeddings_dataset.save_to_disk(\"imdb_top_10k_embeddings_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {k: v for k, v in samples.items() if k != \"embeddings\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series Title: Black Book\n",
      "Overview: In the Nazi-occupied Netherlands during World War II, a Jewish singer infiltrates the regional Gestapo headquarters for the Dutch resistance.\n",
      "Genre: Drama, Thriller, War\n",
      "Scores: 0.9596672058105469\n",
      "Votes: 78563\n",
      "Rating: 7.699999809265137\n",
      "Metascore: 71.0\n",
      "Directors: ['Paul Verhoeven', 'Carice van Houten', 'Sebastian Koch', 'Thom Hoffman', 'Halina Reijn']\n",
      "==================================================\n",
      "\n",
      "Series Title: The Baader Meinhof Complex\n",
      "Overview: A look at Germany's terrorist group, The Red Army Faction (RAF), which organized bombings, robberies, kidnappings, and assassinations in the late 1960s and '70s.\n",
      "Genre: Action, Biography, Crime\n",
      "Scores: 0.9527997374534607\n",
      "Votes: 39026\n",
      "Rating: 7.300000190734863\n",
      "Metascore: 76.0\n",
      "Directors: ['Uli Edel', 'Martina Gedeck', 'Moritz Bleibtreu', 'Johanna Wokalek', 'Bruno Ganz']\n",
      "==================================================\n",
      "\n",
      "Series Title: Look Who's Back\n",
      "Overview: Adolf Hitler wakes up in the 21st century. He quickly gains media attention, but while Germany finds him hilarious and charming, Hitler makes some serious observations about society.\n",
      "Genre: Comedy, Drama, Fantasy\n",
      "Scores: 0.9523625373840332\n",
      "Votes: 47533\n",
      "Rating: 7.0\n",
      "Metascore: nan\n",
      "Directors: ['David Wnendt', 'Oliver Masucci', 'Thomas M. Köppl', 'Marc-Marvin Israel', 'David Gebigke']\n",
      "==================================================\n",
      "\n",
      "Series Title: Europa Europa\n",
      "Overview: A boy in Nazi Germany, trying to conceal that he is Jewish, joins the Hitler Youth.\n",
      "Genre: Drama, History, War\n",
      "Scores: 0.9367366433143616\n",
      "Votes: 16930\n",
      "Rating: 7.599999904632568\n",
      "Metascore: 75.0\n",
      "Directors: ['Agnieszka Holland', 'Solomon Perel', 'Marco Hofschneider', 'René Hofschneider', 'André Wilms']\n",
      "==================================================\n",
      "\n",
      "Series Title: Downfall\n",
      "Overview: Traudl Junge, the final secretary for Adolf Hitler, tells of the Nazi dictator's final days in his Berlin bunker at the end of WWII.\n",
      "Genre: Biography, Drama, History\n",
      "Scores: 0.9109431505203247\n",
      "Votes: 362921\n",
      "Rating: 8.199999809265137\n",
      "Metascore: 82.0\n",
      "Directors: ['Oliver Hirschbiegel', 'Bruno Ganz', 'Alexandra Maria Lara', 'Ulrich Matthes', 'Juliane Köhler']\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, row in samples_df.iterrows():\n",
    "    print(f\"Series Title: {row['Movie Name']}\")\n",
    "    print(f\"Overview: {row['Plot']}\")\n",
    "    print(f\"Genre: {row['Genre']}\")\n",
    "    print(f\"Scores: {row['scores']}\")\n",
    "    print(f\"Votes: {row['Votes']}\")\n",
    "    print(f\"Rating: {row['Rating']}\")\n",
    "    print(f\"Metascore: {row['Metascore']}\")\n",
    "    print(f\"Directors: {row['Directors']}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
